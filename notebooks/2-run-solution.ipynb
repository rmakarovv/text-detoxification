{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Clone repository and install requirements"
      ],
      "metadata": {
        "id": "-X-NdXxQaefj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyITW0mMjKXu",
        "outputId": "e89df3a2-4365-4afe-db47-d35c132dcf6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'text-detoxification'...\n",
            "remote: Enumerating objects: 98, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 98 (delta 26), reused 78 (delta 14), pack-reused 7\u001b[K\n",
            "Receiving objects: 100% (98/98), 44.37 MiB | 32.11 MiB/s, done.\n",
            "Resolving deltas: 100% (26/26), done.\n",
            "Filtering content: 100% (2/2), 251.20 MiB | 33.49 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://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@github.com/rmakarovv/text-detoxification.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install -r text-detoxification/requirements.txt"
      ],
      "metadata": {
        "id": "b606c1-ulOXW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Training"
      ],
      "metadata": {
        "id": "VtCECDpIamxw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run a cell below only if you want to train the model from scratch (approximately 1 hour on T4 GPU)"
      ],
      "metadata": {
        "id": "Sp2utb0Eaqa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python text-detoxification/src/models/train_model.py"
      ],
      "metadata": {
        "id": "5vrG3qBaQIo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model testing"
      ],
      "metadata": {
        "id": "Rvjwp9Ngaoek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell allows us to run the solution and input sentences that we want to detoxify"
      ],
      "metadata": {
        "id": "XcH7fup0ay0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python text-detoxification/src/models/predict_model.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkUZ-4umk8Ou",
        "outputId": "806cc368-7e33-40b7-ee5c-9027d822fecc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading (…)okenizer_config.json: 100% 2.32k/2.32k [00:00<00:00, 13.1MB/s]\n",
            "Downloading (…)ve/main/spiece.model: 100% 792k/792k [00:00<00:00, 11.7MB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100% 1.39M/1.39M [00:00<00:00, 17.3MB/s]\n",
            "Input sentence that you want to detoxify or press ENTER to exit:\n",
            "Damn It!\n",
            "Detoxified text: do it!\n",
            "Input sentence that you want to detoxify or press ENTER to exit:\n",
            "I'll bloody well walk out of here.\n",
            "Detoxified text: i'll walk out of here.\n",
            "Input sentence that you want to detoxify or press ENTER to exit:\n",
            "\n"
          ]
        }
      ]
    }
  ]
}