{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##Clone repository and install requirements","metadata":{}},{"cell_type":"code","source":"!git config --global http.sslVerify false","metadata":{"execution":{"iopub.status.busy":"2023-10-23T16:38:31.789180Z","iopub.execute_input":"2023-10-23T16:38:31.789818Z","iopub.status.idle":"2023-10-23T16:38:32.747067Z","shell.execute_reply.started":"2023-10-23T16:38:31.789785Z","shell.execute_reply":"2023-10-23T16:38:32.745526Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!git clone https://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@github.com/rmakarovv/text-detoxification.git","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fyITW0mMjKXu","outputId":"a2b46d78-3ef9-4137-f791-94237d799b0f","execution":{"iopub.status.busy":"2023-10-23T16:38:32.748973Z","iopub.execute_input":"2023-10-23T16:38:32.749307Z","iopub.status.idle":"2023-10-23T16:38:38.278276Z","shell.execute_reply.started":"2023-10-23T16:38:32.749276Z","shell.execute_reply":"2023-10-23T16:38:38.277291Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'text-detoxification'...\nremote: Enumerating objects: 285, done.\u001b[K\nremote: Counting objects: 100% (15/15), done.\u001b[K\nremote: Compressing objects: 100% (12/12), done.\u001b[K\nremote: Total 285 (delta 4), reused 13 (delta 3), pack-reused 270\u001b[K\nReceiving objects: 100% (285/285), 48.06 MiB | 16.25 MiB/s, done.\nResolving deltas: 100% (106/106), done.\nDownloading data/raw/filtered_paranmt.zip (44 MB)\nError downloading object: data/raw/filtered_paranmt.zip (4f1dff5): Smudge error: Error downloading data/raw/filtered_paranmt.zip (4f1dff549581604e678a9cee0180f38bc33342b24ccfa06d513449336186bded): batch response: This repository is over its data quota. Account responsible for LFS bandwidth should purchase more data packs to restore access.\n\nErrors logged to /kaggle/working/text-detoxification/.git/lfs/logs/20231023T163838.171153428.log\nUse `git lfs logs last` to view the log.\nerror: external filter 'git-lfs filter-process' failed\nfatal: data/raw/filtered_paranmt.zip: smudge filter lfs failed\nwarning: Clone succeeded, but checkout failed.\nYou can inspect what was checked out with 'git status'\nand retry with 'git restore --source=HEAD :/'\n\n","output_type":"stream"}]},{"cell_type":"code","source":"%%capture\n!pip install -r text-detoxification/requirements.txt","metadata":{"id":"b606c1-ulOXW","execution":{"iopub.status.busy":"2023-10-23T16:38:38.280212Z","iopub.execute_input":"2023-10-23T16:38:38.280517Z","iopub.status.idle":"2023-10-23T16:38:55.410782Z","shell.execute_reply.started":"2023-10-23T16:38:38.280489Z","shell.execute_reply":"2023-10-23T16:38:55.409499Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"##Preparing dataset","metadata":{"id":"huRCRBFZZKM7"}},{"cell_type":"code","source":"!python text-detoxification/src/data/make_dataset.py","metadata":{"id":"Y9XI_QkkZI3q","execution":{"iopub.status.busy":"2023-10-23T16:38:55.412225Z","iopub.execute_input":"2023-10-23T16:38:55.412516Z","iopub.status.idle":"2023-10-23T16:39:02.135251Z","shell.execute_reply.started":"2023-10-23T16:38:55.412489Z","shell.execute_reply":"2023-10-23T16:39:02.134193Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"100% [....................................................] 44376072 / 44376072","output_type":"stream"}]},{"cell_type":"markdown","source":"##Model Training","metadata":{"id":"VtCECDpIamxw"}},{"cell_type":"markdown","source":"Run cells below only if you want to train the model from scratch (approximately 1.2 hours on GPU)","metadata":{"id":"Sp2utb0Eaqa0"}},{"cell_type":"code","source":"import torch\ntorch.manual_seed(42)","metadata":{"execution":{"iopub.status.busy":"2023-10-23T16:39:02.138014Z","iopub.execute_input":"2023-10-23T16:39:02.138755Z","iopub.status.idle":"2023-10-23T16:39:05.120112Z","shell.execute_reply.started":"2023-10-23T16:39:02.138715Z","shell.execute_reply":"2023-10-23T16:39:05.119179Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7f70f02a6910>"},"metadata":{}}]},{"cell_type":"code","source":"!python text-detoxification/src/models/train_model.py","metadata":{"id":"5vrG3qBaQIo7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c04c3a13-a9ce-4de5-8b43-852dd7db7a3e","execution":{"iopub.status.busy":"2023-10-23T16:39:05.121369Z","iopub.execute_input":"2023-10-23T16:39:05.121837Z","iopub.status.idle":"2023-10-23T17:39:32.668715Z","shell.execute_reply.started":"2023-10-23T16:39:05.121804Z","shell.execute_reply":"2023-10-23T17:39:32.667521Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\nDownloading (…)okenizer_config.json: 100%|█| 2.32k/2.32k [00:00<00:00, 13.8MB/s]\nDownloading (…)ve/main/spiece.model: 100%|███| 792k/792k [00:00<00:00, 11.6MB/s]\nDownloading (…)/main/tokenizer.json: 100%|█| 1.39M/1.39M [00:00<00:00, 7.78MB/s]\nDownloading (…)lve/main/config.json: 100%|█| 1.21k/1.21k [00:00<00:00, 10.2MB/s]\nDownloading model.safetensors: 100%|██████████| 242M/242M [00:00<00:00, 300MB/s]\nDownloading (…)neration_config.json: 100%|█████| 147/147 [00:00<00:00, 1.02MB/s]\nDownloading (…)821d1/.gitattributes: 100%|█████| 391/391 [00:00<00:00, 2.37MB/s]\nDownloading (…)_Pooling/config.json: 100%|█████| 190/190 [00:00<00:00, 1.10MB/s]\nDownloading (…)8d01e821d1/README.md: 100%|█| 3.95k/3.95k [00:00<00:00, 21.9MB/s]\nDownloading (…)d1/added_tokens.json: 100%|███| 2.00/2.00 [00:00<00:00, 12.0kB/s]\nDownloading (…)01e821d1/config.json: 100%|█████| 625/625 [00:00<00:00, 3.51MB/s]\nDownloading (…)ce_transformers.json: 100%|██████| 122/122 [00:00<00:00, 737kB/s]\nDownloading pytorch_model.bin: 100%|██████████| 438M/438M [00:01<00:00, 328MB/s]\nDownloading (…)nce_bert_config.json: 100%|████| 53.0/53.0 [00:00<00:00, 400kB/s]\nDownloading (…)cial_tokens_map.json: 100%|██████| 112/112 [00:00<00:00, 622kB/s]\nDownloading (…)821d1/tokenizer.json: 100%|███| 466k/466k [00:00<00:00, 13.7MB/s]\nDownloading (…)okenizer_config.json: 100%|█████| 399/399 [00:00<00:00, 2.73MB/s]\nDownloading (…)8d01e821d1/vocab.txt: 100%|███| 232k/232k [00:00<00:00, 1.89MB/s]\nDownloading (…)1e821d1/modules.json: 100%|█████| 229/229 [00:00<00:00, 1.72MB/s]\nYou're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n{'loss': 1.3994, 'learning_rate': 1.92998669747252e-05, 'epoch': 0.11}\n{'loss': 0.4066, 'learning_rate': 1.85997339494504e-05, 'epoch': 0.21}\n{'loss': 0.3819, 'learning_rate': 1.7899600924175596e-05, 'epoch': 0.32}\n{'loss': 0.379, 'learning_rate': 1.7199467898900793e-05, 'epoch': 0.42}\n{'loss': 0.3685, 'learning_rate': 1.649933487362599e-05, 'epoch': 0.53}\n{'loss': 0.3647, 'learning_rate': 1.579920184835119e-05, 'epoch': 0.63}\n{'loss': 0.3586, 'learning_rate': 1.5099068823076386e-05, 'epoch': 0.74}\n{'loss': 0.3533, 'learning_rate': 1.4398935797801582e-05, 'epoch': 0.84}\n{'loss': 0.357, 'learning_rate': 1.369880277252678e-05, 'epoch': 0.95}\nBatches: 100%|██████████████████████████████| 1190/1190 [00:22<00:00, 52.65it/s]\nBatches: 100%|██████████████████████████████| 1190/1190 [00:24<00:00, 48.42it/s]\n{'eval_loss': 0.3166199326515198, 'eval_bert_simil': 0.8100000023841858, 'eval_runtime': 335.5473, 'eval_samples_per_second': 113.486, 'eval_steps_per_second': 3.546, 'epoch': 1.0}\n{'loss': 0.351, 'learning_rate': 1.299866974725198e-05, 'epoch': 1.05}\n{'loss': 0.3443, 'learning_rate': 1.2298536721977177e-05, 'epoch': 1.16}\n{'loss': 0.3452, 'learning_rate': 1.1598403696702374e-05, 'epoch': 1.26}\n{'loss': 0.3459, 'learning_rate': 1.0898270671427572e-05, 'epoch': 1.37}\n{'loss': 0.3438, 'learning_rate': 1.0198137646152771e-05, 'epoch': 1.47}\n{'loss': 0.3456, 'learning_rate': 9.498004620877968e-06, 'epoch': 1.58}\n{'loss': 0.3457, 'learning_rate': 8.797871595603165e-06, 'epoch': 1.68}\n{'loss': 0.3439, 'learning_rate': 8.097738570328364e-06, 'epoch': 1.79}\n{'loss': 0.3392, 'learning_rate': 7.3976055450535615e-06, 'epoch': 1.89}\n{'loss': 0.3352, 'learning_rate': 6.6974725197787585e-06, 'epoch': 2.0}\nBatches: 100%|██████████████████████████████| 1190/1190 [00:22<00:00, 52.73it/s]\nBatches: 100%|██████████████████████████████| 1190/1190 [00:24<00:00, 48.42it/s]\n{'eval_loss': 0.30723121762275696, 'eval_bert_simil': 0.8140000104904175, 'eval_runtime': 334.5247, 'eval_samples_per_second': 113.833, 'eval_steps_per_second': 3.557, 'epoch': 2.0}\n{'loss': 0.3371, 'learning_rate': 5.997339494503956e-06, 'epoch': 2.1}\n{'loss': 0.337, 'learning_rate': 5.297206469229153e-06, 'epoch': 2.21}\n{'loss': 0.3375, 'learning_rate': 4.597073443954352e-06, 'epoch': 2.31}\n{'loss': 0.3335, 'learning_rate': 3.89694041867955e-06, 'epoch': 2.42}\n{'loss': 0.3333, 'learning_rate': 3.196807393404747e-06, 'epoch': 2.52}\n{'loss': 0.3365, 'learning_rate': 2.496674368129945e-06, 'epoch': 2.63}\n{'loss': 0.3347, 'learning_rate': 1.7965413428551426e-06, 'epoch': 2.73}\n{'loss': 0.3387, 'learning_rate': 1.0964083175803404e-06, 'epoch': 2.84}\n{'loss': 0.3352, 'learning_rate': 3.962752923055381e-07, 'epoch': 2.94}\nBatches: 100%|██████████████████████████████| 1190/1190 [00:22<00:00, 52.53it/s]\nBatches: 100%|██████████████████████████████| 1190/1190 [00:24<00:00, 48.44it/s]\n{'eval_loss': 0.3048833906650543, 'eval_bert_simil': 0.8159999847412109, 'eval_runtime': 333.5715, 'eval_samples_per_second': 114.158, 'eval_steps_per_second': 3.567, 'epoch': 3.0}\n{'train_runtime': 3553.9034, 'train_samples_per_second': 128.581, 'train_steps_per_second': 4.019, 'train_loss': 0.3859318155856107, 'epoch': 3.0}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"##Model testing","metadata":{"id":"Rvjwp9Ngaoek"}},{"cell_type":"markdown","source":"The following cell allows us to run the solution and input sentences that we want to detoxify","metadata":{"id":"XcH7fup0ay0b"}},{"cell_type":"code","source":"!python text-detoxification/src/models/predict_model.py","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VkUZ-4umk8Ou","outputId":"806cc368-7e33-40b7-ee5c-9027d822fecc","execution":{"iopub.status.busy":"2023-10-23T17:39:32.670735Z","iopub.execute_input":"2023-10-23T17:39:32.671647Z","iopub.status.idle":"2023-10-23T17:39:51.326343Z","shell.execute_reply.started":"2023-10-23T17:39:32.671586Z","shell.execute_reply":"2023-10-23T17:39:51.325383Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\nOriginal:    His father would have used a booming voice to wrench a reply from this stupid machine.\nParaphrase:  his father would have used a booming voice to get a reply from this machine.\nOriginal:    You have to send those idiots back in.\nParaphrase:  you have to send them back.\nOriginal:    Salina could be with that stupid cop.\nParaphrase:  Salina could be with the cop.\nOriginal:    And don't let those idiots in radiology hold you up.\nParaphrase:  and don't let those radiologists hold you up.\nOriginal:    My idiot friend here brought marijuana... - on the plane.\nParaphrase:  my friend brought marijuana on the plane.\nOriginal:    That stupid couple told her to break up with you.\nParaphrase:  the couple told her to break up with you.\nOriginal:    The idiot, Max. He never should have sold it to you guys.\nParaphrase:  Max, he never should have sold it to you.\nOriginal:    Fuck you, soft. You're panicking\nParaphrase:  you're panicking.\nOriginal:    It's coz of those two idiots. They escaped through a tunnel.\nParaphrase:  they escaped through a tunnel.\nOriginal:    You have to let this stupid plane crash make the decision for you.\nParaphrase:  you have to let this plane crash make the decision for you.\nOriginal:    Audrey Cruz is an idiot. He's the boss.\nParaphrase:  Audrey Cruz is a boss.\nOriginal:    Why don't you get a job. Instead of playing golf with your stupid buddies?\nParaphrase:  why don't you get a job instead of playing golf with your buddies?\nOriginal:    How do you like your stupid game now, Tom?\nParaphrase:  how do you like your game now, Tom?\nOriginal:    Think about that shit, dawg.\nParaphrase:  think about that, dawg.\nOriginal:    You idiots! You have betrayed the revolution.\nParaphrase:  you have betrayed the revolution.\nOriginal:    Why is this idiot Silencer shouting so much?\nParaphrase:  why is Silencer so loud?\nOriginal:    Just like the rest of the stupid Irish in this country.\nParaphrase:  like the rest of the Irish in this country.\nOriginal:    Your shit is so tired, Justice.\nParaphrase:  you're so tired, Justice.\nOriginal:    More than the stupid senators and congressmen that passed it.\nParaphrase:  more than the stupid senators and congressmen who passed it.\n","output_type":"stream"}]},{"cell_type":"code","source":"!cp text-detoxification/models/best.zip best.zip\n!cp text-detoxification/reports/figures/training.pdf training.pdf","metadata":{"execution":{"iopub.status.busy":"2023-10-23T17:39:51.328134Z","iopub.execute_input":"2023-10-23T17:39:51.329049Z","iopub.status.idle":"2023-10-23T17:39:53.427783Z","shell.execute_reply.started":"2023-10-23T17:39:51.329006Z","shell.execute_reply":"2023-10-23T17:39:53.426431Z"},"trusted":true},"execution_count":8,"outputs":[]}]}