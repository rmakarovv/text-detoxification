{"cells":[{"cell_type":"markdown","metadata":{},"source":["##Clone repository and install requirements"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T16:38:31.789818Z","iopub.status.busy":"2023-10-23T16:38:31.789180Z","iopub.status.idle":"2023-10-23T16:38:32.747067Z","shell.execute_reply":"2023-10-23T16:38:32.745526Z","shell.execute_reply.started":"2023-10-23T16:38:31.789785Z"},"trusted":true},"outputs":[],"source":["!git config --global http.sslVerify false"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-10-23T16:38:32.749307Z","iopub.status.busy":"2023-10-23T16:38:32.748973Z","iopub.status.idle":"2023-10-23T16:38:38.278276Z","shell.execute_reply":"2023-10-23T16:38:38.277291Z","shell.execute_reply.started":"2023-10-23T16:38:32.749276Z"},"id":"fyITW0mMjKXu","outputId":"a2b46d78-3ef9-4137-f791-94237d799b0f","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'text-detoxification'...\n","remote: Enumerating objects: 285, done.\u001b[K\n","remote: Counting objects: 100% (15/15), done.\u001b[K\n","remote: Compressing objects: 100% (12/12), done.\u001b[K\n","remote: Total 285 (delta 4), reused 13 (delta 3), pack-reused 270\u001b[K\n","Receiving objects: 100% (285/285), 48.06 MiB | 16.25 MiB/s, done.\n","Resolving deltas: 100% (106/106), done.\n","Downloading data/raw/filtered_paranmt.zip (44 MB)\n","Error downloading object: data/raw/filtered_paranmt.zip (4f1dff5): Smudge error: Error downloading data/raw/filtered_paranmt.zip (4f1dff549581604e678a9cee0180f38bc33342b24ccfa06d513449336186bded): batch response: This repository is over its data quota. Account responsible for LFS bandwidth should purchase more data packs to restore access.\n","\n","Errors logged to /kaggle/working/text-detoxification/.git/lfs/logs/20231023T163838.171153428.log\n","Use `git lfs logs last` to view the log.\n","error: external filter 'git-lfs filter-process' failed\n","fatal: data/raw/filtered_paranmt.zip: smudge filter lfs failed\n","warning: Clone succeeded, but checkout failed.\n","You can inspect what was checked out with 'git status'\n","and retry with 'git restore --source=HEAD :/'\n","\n"]}],"source":["!git clone https://github.com/rmakarovv/text-detoxification.git"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T16:38:38.280517Z","iopub.status.busy":"2023-10-23T16:38:38.280212Z","iopub.status.idle":"2023-10-23T16:38:55.410782Z","shell.execute_reply":"2023-10-23T16:38:55.409499Z","shell.execute_reply.started":"2023-10-23T16:38:38.280489Z"},"id":"b606c1-ulOXW","trusted":true},"outputs":[],"source":["%%capture\n","!pip install -r text-detoxification/requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"huRCRBFZZKM7"},"source":["##Preparing dataset"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T16:38:55.412516Z","iopub.status.busy":"2023-10-23T16:38:55.412225Z","iopub.status.idle":"2023-10-23T16:39:02.135251Z","shell.execute_reply":"2023-10-23T16:39:02.134193Z","shell.execute_reply.started":"2023-10-23T16:38:55.412489Z"},"id":"Y9XI_QkkZI3q","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["100% [....................................................] 44376072 / 44376072"]}],"source":["!python text-detoxification/src/data/make_dataset.py"]},{"cell_type":"markdown","metadata":{"id":"VtCECDpIamxw"},"source":["##Model Training"]},{"cell_type":"markdown","metadata":{"id":"Sp2utb0Eaqa0"},"source":["Run cells below only if you want to train the model from scratch (approximately 1.2 hours on GPU)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T16:39:02.138755Z","iopub.status.busy":"2023-10-23T16:39:02.138014Z","iopub.status.idle":"2023-10-23T16:39:05.120112Z","shell.execute_reply":"2023-10-23T16:39:05.119179Z","shell.execute_reply.started":"2023-10-23T16:39:02.138715Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x7f70f02a6910>"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","torch.manual_seed(42)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-10-23T16:39:05.121837Z","iopub.status.busy":"2023-10-23T16:39:05.121369Z","iopub.status.idle":"2023-10-23T17:39:32.668715Z","shell.execute_reply":"2023-10-23T17:39:32.667521Z","shell.execute_reply.started":"2023-10-23T16:39:05.121804Z"},"id":"5vrG3qBaQIo7","outputId":"c04c3a13-a9ce-4de5-8b43-852dd7db7a3e","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","Downloading (…)okenizer_config.json: 100%|█| 2.32k/2.32k [00:00<00:00, 13.8MB/s]\n","Downloading (…)ve/main/spiece.model: 100%|███| 792k/792k [00:00<00:00, 11.6MB/s]\n","Downloading (…)/main/tokenizer.json: 100%|█| 1.39M/1.39M [00:00<00:00, 7.78MB/s]\n","Downloading (…)lve/main/config.json: 100%|█| 1.21k/1.21k [00:00<00:00, 10.2MB/s]\n","Downloading model.safetensors: 100%|██████████| 242M/242M [00:00<00:00, 300MB/s]\n","Downloading (…)neration_config.json: 100%|█████| 147/147 [00:00<00:00, 1.02MB/s]\n","Downloading (…)821d1/.gitattributes: 100%|█████| 391/391 [00:00<00:00, 2.37MB/s]\n","Downloading (…)_Pooling/config.json: 100%|█████| 190/190 [00:00<00:00, 1.10MB/s]\n","Downloading (…)8d01e821d1/README.md: 100%|█| 3.95k/3.95k [00:00<00:00, 21.9MB/s]\n","Downloading (…)d1/added_tokens.json: 100%|███| 2.00/2.00 [00:00<00:00, 12.0kB/s]\n","Downloading (…)01e821d1/config.json: 100%|█████| 625/625 [00:00<00:00, 3.51MB/s]\n","Downloading (…)ce_transformers.json: 100%|██████| 122/122 [00:00<00:00, 737kB/s]\n","Downloading pytorch_model.bin: 100%|██████████| 438M/438M [00:01<00:00, 328MB/s]\n","Downloading (…)nce_bert_config.json: 100%|████| 53.0/53.0 [00:00<00:00, 400kB/s]\n","Downloading (…)cial_tokens_map.json: 100%|██████| 112/112 [00:00<00:00, 622kB/s]\n","Downloading (…)821d1/tokenizer.json: 100%|███| 466k/466k [00:00<00:00, 13.7MB/s]\n","Downloading (…)okenizer_config.json: 100%|█████| 399/399 [00:00<00:00, 2.73MB/s]\n","Downloading (…)8d01e821d1/vocab.txt: 100%|███| 232k/232k [00:00<00:00, 1.89MB/s]\n","Downloading (…)1e821d1/modules.json: 100%|█████| 229/229 [00:00<00:00, 1.72MB/s]\n","You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","{'loss': 1.3994, 'learning_rate': 1.92998669747252e-05, 'epoch': 0.11}\n","{'loss': 0.4066, 'learning_rate': 1.85997339494504e-05, 'epoch': 0.21}\n","{'loss': 0.3819, 'learning_rate': 1.7899600924175596e-05, 'epoch': 0.32}\n","{'loss': 0.379, 'learning_rate': 1.7199467898900793e-05, 'epoch': 0.42}\n","{'loss': 0.3685, 'learning_rate': 1.649933487362599e-05, 'epoch': 0.53}\n","{'loss': 0.3647, 'learning_rate': 1.579920184835119e-05, 'epoch': 0.63}\n","{'loss': 0.3586, 'learning_rate': 1.5099068823076386e-05, 'epoch': 0.74}\n","{'loss': 0.3533, 'learning_rate': 1.4398935797801582e-05, 'epoch': 0.84}\n","{'loss': 0.357, 'learning_rate': 1.369880277252678e-05, 'epoch': 0.95}\n","Batches: 100%|██████████████████████████████| 1190/1190 [00:22<00:00, 52.65it/s]\n","Batches: 100%|██████████████████████████████| 1190/1190 [00:24<00:00, 48.42it/s]\n","{'eval_loss': 0.3166199326515198, 'eval_bert_simil': 0.8100000023841858, 'eval_runtime': 335.5473, 'eval_samples_per_second': 113.486, 'eval_steps_per_second': 3.546, 'epoch': 1.0}\n","{'loss': 0.351, 'learning_rate': 1.299866974725198e-05, 'epoch': 1.05}\n","{'loss': 0.3443, 'learning_rate': 1.2298536721977177e-05, 'epoch': 1.16}\n","{'loss': 0.3452, 'learning_rate': 1.1598403696702374e-05, 'epoch': 1.26}\n","{'loss': 0.3459, 'learning_rate': 1.0898270671427572e-05, 'epoch': 1.37}\n","{'loss': 0.3438, 'learning_rate': 1.0198137646152771e-05, 'epoch': 1.47}\n","{'loss': 0.3456, 'learning_rate': 9.498004620877968e-06, 'epoch': 1.58}\n","{'loss': 0.3457, 'learning_rate': 8.797871595603165e-06, 'epoch': 1.68}\n","{'loss': 0.3439, 'learning_rate': 8.097738570328364e-06, 'epoch': 1.79}\n","{'loss': 0.3392, 'learning_rate': 7.3976055450535615e-06, 'epoch': 1.89}\n","{'loss': 0.3352, 'learning_rate': 6.6974725197787585e-06, 'epoch': 2.0}\n","Batches: 100%|██████████████████████████████| 1190/1190 [00:22<00:00, 52.73it/s]\n","Batches: 100%|██████████████████████████████| 1190/1190 [00:24<00:00, 48.42it/s]\n","{'eval_loss': 0.30723121762275696, 'eval_bert_simil': 0.8140000104904175, 'eval_runtime': 334.5247, 'eval_samples_per_second': 113.833, 'eval_steps_per_second': 3.557, 'epoch': 2.0}\n","{'loss': 0.3371, 'learning_rate': 5.997339494503956e-06, 'epoch': 2.1}\n","{'loss': 0.337, 'learning_rate': 5.297206469229153e-06, 'epoch': 2.21}\n","{'loss': 0.3375, 'learning_rate': 4.597073443954352e-06, 'epoch': 2.31}\n","{'loss': 0.3335, 'learning_rate': 3.89694041867955e-06, 'epoch': 2.42}\n","{'loss': 0.3333, 'learning_rate': 3.196807393404747e-06, 'epoch': 2.52}\n","{'loss': 0.3365, 'learning_rate': 2.496674368129945e-06, 'epoch': 2.63}\n","{'loss': 0.3347, 'learning_rate': 1.7965413428551426e-06, 'epoch': 2.73}\n","{'loss': 0.3387, 'learning_rate': 1.0964083175803404e-06, 'epoch': 2.84}\n","{'loss': 0.3352, 'learning_rate': 3.962752923055381e-07, 'epoch': 2.94}\n","Batches: 100%|██████████████████████████████| 1190/1190 [00:22<00:00, 52.53it/s]\n","Batches: 100%|██████████████████████████████| 1190/1190 [00:24<00:00, 48.44it/s]\n","{'eval_loss': 0.3048833906650543, 'eval_bert_simil': 0.8159999847412109, 'eval_runtime': 333.5715, 'eval_samples_per_second': 114.158, 'eval_steps_per_second': 3.567, 'epoch': 3.0}\n","{'train_runtime': 3553.9034, 'train_samples_per_second': 128.581, 'train_steps_per_second': 4.019, 'train_loss': 0.3859318155856107, 'epoch': 3.0}\n"]}],"source":["!python text-detoxification/src/models/train_model.py"]},{"cell_type":"markdown","metadata":{"id":"Rvjwp9Ngaoek"},"source":["##Model testing"]},{"cell_type":"markdown","metadata":{"id":"XcH7fup0ay0b"},"source":["The following cell allows us to run the solution and input sentences that we want to detoxify"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-10-23T17:39:32.671647Z","iopub.status.busy":"2023-10-23T17:39:32.670735Z","iopub.status.idle":"2023-10-23T17:39:51.326343Z","shell.execute_reply":"2023-10-23T17:39:51.325383Z","shell.execute_reply.started":"2023-10-23T17:39:32.671586Z"},"id":"VkUZ-4umk8Ou","outputId":"806cc368-7e33-40b7-ee5c-9027d822fecc","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","Original:    His father would have used a booming voice to wrench a reply from this stupid machine.\n","Paraphrase:  his father would have used a booming voice to get a reply from this machine.\n","Original:    You have to send those idiots back in.\n","Paraphrase:  you have to send them back.\n","Original:    Salina could be with that stupid cop.\n","Paraphrase:  Salina could be with the cop.\n","Original:    And don't let those idiots in radiology hold you up.\n","Paraphrase:  and don't let those radiologists hold you up.\n","Original:    My idiot friend here brought marijuana... - on the plane.\n","Paraphrase:  my friend brought marijuana on the plane.\n","Original:    That stupid couple told her to break up with you.\n","Paraphrase:  the couple told her to break up with you.\n","Original:    The idiot, Max. He never should have sold it to you guys.\n","Paraphrase:  Max, he never should have sold it to you.\n","Original:    Fuck you, soft. You're panicking\n","Paraphrase:  you're panicking.\n","Original:    It's coz of those two idiots. They escaped through a tunnel.\n","Paraphrase:  they escaped through a tunnel.\n","Original:    You have to let this stupid plane crash make the decision for you.\n","Paraphrase:  you have to let this plane crash make the decision for you.\n","Original:    Audrey Cruz is an idiot. He's the boss.\n","Paraphrase:  Audrey Cruz is a boss.\n","Original:    Why don't you get a job. Instead of playing golf with your stupid buddies?\n","Paraphrase:  why don't you get a job instead of playing golf with your buddies?\n","Original:    How do you like your stupid game now, Tom?\n","Paraphrase:  how do you like your game now, Tom?\n","Original:    Think about that shit, dawg.\n","Paraphrase:  think about that, dawg.\n","Original:    You idiots! You have betrayed the revolution.\n","Paraphrase:  you have betrayed the revolution.\n","Original:    Why is this idiot Silencer shouting so much?\n","Paraphrase:  why is Silencer so loud?\n","Original:    Just like the rest of the stupid Irish in this country.\n","Paraphrase:  like the rest of the Irish in this country.\n","Original:    Your shit is so tired, Justice.\n","Paraphrase:  you're so tired, Justice.\n","Original:    More than the stupid senators and congressmen that passed it.\n","Paraphrase:  more than the stupid senators and congressmen who passed it.\n"]}],"source":["!python text-detoxification/src/models/predict_model.py"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
